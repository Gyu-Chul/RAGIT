"""
RAG Worker íƒœìŠ¤í¬ ì •ì˜
"""

import time
from typing import Dict, Any, Union, Optional, List
from .celery_app import app
from .git_service import GitService
from .git_service.types import CloneResult, StatusResult, PullResult, DeleteResult
from .python_parser import RepositoryParserService
from .python_parser.types import RepositoryParseResult
from .vector_db import VectorDBService
from .vector_db.types import EmbeddingResult, SearchResult
from .vector_db.config import DEFAULT_MODEL_KEY
from .ask_question import AskQuestion, PromptGenerator

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
git_service = GitService()
parser_service = RepositoryParserService()
# embedding_batch_size=4: ë©”ëª¨ë¦¬ ëˆ„ì  ë°©ì§€, ë°°ì¹˜ë§ˆë‹¤ ë©”ëª¨ë¦¬ í•´ì œ
vector_db_service = VectorDBService(embedding_batch_size=4)
prompt_service = PromptGenerator()
call_service = AskQuestion()

@app.task
def process_document(document_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë¬¸ì„œ ì²˜ë¦¬ íƒœìŠ¤í¬

    Args:
        document_data: ì²˜ë¦¬í•  ë¬¸ì„œ ë°ì´í„°

    Returns:
        ì²˜ë¦¬ ê²°ê³¼
    """
    # TODO: ì‹¤ì œ ë¬¸ì„œ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„
    return {
        "status": "processed",
        "document_id": document_data.get("id"),
        "message": "Document processed successfully"
    }


@app.task
def search_documents(query: str, limit: int = 10) -> Dict[str, Any]:
    """
    ë¬¸ì„œ ê²€ìƒ‰ íƒœìŠ¤í¬

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        limit: ê²°ê³¼ ì œí•œ ìˆ˜

    Returns:
        ê²€ìƒ‰ ê²°ê³¼
    """
    # TODO: ì‹¤ì œ ê²€ìƒ‰ ë¡œì§ êµ¬í˜„
    return {
        "query": query,
        "results": [],
        "total": 0,
        "message": "Search completed"
    }


@app.task
def health_check() -> Dict[str, str]:
    """
    í—¬ìŠ¤ ì²´í¬ íƒœìŠ¤í¬

    Returns:
        ìƒíƒœ ì •ë³´
    """
    return {"status": "healthy", "service": "rag_worker"}


# í…ŒìŠ¤íŠ¸ìš© ê¸°ë³¸ íƒœìŠ¤í¬
@app.task
def add(x: Union[int, float], y: Union[int, float]) -> Union[int, float]:
    """ë‘ ìˆ«ìë¥¼ ë”í•˜ëŠ” ì‘ì—…"""
    result = x + y
    return result


@app.task
def reverse_string(text: str) -> str:
    """ë¬¸ìì—´ì„ ë’¤ì§‘ëŠ” ì‘ì—…"""
    result = text[::-1]
    return result


@app.task
def wait_seconds(second: int) -> int:
    """ì§€ì •ëœ ì‹œê°„ë§Œí¼ ëŒ€ê¸°í•˜ëŠ” ì‘ì—…"""
    time.sleep(second)
    return second


# Git ê´€ë ¨ ì‘ì—…
@app.task
def git_clone(git_url: str, repo_name: Optional[str] = None) -> CloneResult:
    """
    Git ë ˆí¬ì§€í† ë¦¬ í´ë¡  ì‘ì—…

    Args:
        git_url: Git ë ˆí¬ì§€í† ë¦¬ URL
        repo_name: ì €ì¥í•  ë ˆí¬ì§€í† ë¦¬ ì´ë¦„ (ì„ íƒ)

    Returns:
        í´ë¡  ê²°ê³¼
    """
    return git_service.clone_repository(git_url, repo_name)


@app.task
def git_check_status(repo_name: str) -> StatusResult:
    """
    ë ˆí¬ì§€í† ë¦¬ ì»¤ë°‹ ìƒíƒœ í™•ì¸ ì‘ì—…

    Args:
        repo_name: ë ˆí¬ì§€í† ë¦¬ ì´ë¦„

    Returns:
        ì»¤ë°‹ ìƒíƒœ ì •ë³´
    """
    return git_service.check_commit_status(repo_name)


@app.task
def git_pull(repo_name: str) -> PullResult:
    """
    ë ˆí¬ì§€í† ë¦¬ pull ì‘ì—…

    Args:
        repo_name: ë ˆí¬ì§€í† ë¦¬ ì´ë¦„

    Returns:
        Pull ê²°ê³¼
    """
    return git_service.pull_repository(repo_name)


@app.task
def git_delete(repo_name: str) -> DeleteResult:
    """
    ë ˆí¬ì§€í† ë¦¬ ì‚­ì œ ì‘ì—…

    Args:
        repo_name: ë ˆí¬ì§€í† ë¦¬ ì´ë¦„

    Returns:
        ì‚­ì œ ê²°ê³¼
    """
    return git_service.delete_repository(repo_name)


# Python íŒŒì‹± ê´€ë ¨ ì‘ì—…
@app.task
def parse_repository(repo_name: str, save_json: bool = True) -> RepositoryParseResult:
    """
    ë ˆí¬ì§€í† ë¦¬ ë‚´ ëª¨ë“  Python íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì²­í‚¹

    Args:
        repo_name: ë ˆí¬ì§€í† ë¦¬ ì´ë¦„
        save_json: JSON íŒŒì¼ë¡œ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)

    Returns:
        ë ˆí¬ì§€í† ë¦¬ íŒŒì‹± ê²°ê³¼
    """
    return parser_service.parse_repository(repo_name, save_json)


# Vector DB ê´€ë ¨ ì‘ì—…
@app.task
def embed_documents(
    json_path: str, collection_name: str, model_key: str = DEFAULT_MODEL_KEY
) -> EmbeddingResult:
    """
    JSON íŒŒì¼ì˜ ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ì—¬ Milvus ì»¬ë ‰ì…˜ì— ì €ì¥

    Args:
        json_path: JSON íŒŒì¼ ê²½ë¡œ
        collection_name: ì €ì¥í•  ì»¬ë ‰ì…˜ ì´ë¦„
        model_key: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ í‚¤ (ê¸°ë³¸ê°’: DEFAULT_MODEL_KEY)

    Returns:
        ì„ë² ë”© ê²°ê³¼
    """
    return vector_db_service.embed_documents(json_path, collection_name, model_key)


@app.task
def embed_repository(
    repo_name: str, collection_name: str, model_key: str = DEFAULT_MODEL_KEY
) -> EmbeddingResult:
    """
    íŒŒì‹±ëœ ë ˆí¬ì§€í† ë¦¬ ì „ì²´ë¥¼ ì„ë² ë”©í•˜ì—¬ Milvus ì»¬ë ‰ì…˜ì— ì €ì¥

    Args:
        repo_name: ë ˆí¬ì§€í† ë¦¬ ì´ë¦„ (parsed_repository/{repo_name}/ ì˜ ëª¨ë“  JSON ìˆ˜ì§‘)
        collection_name: ì €ì¥í•  ì»¬ë ‰ì…˜ ì´ë¦„
        model_key: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ í‚¤ (ê¸°ë³¸ê°’: DEFAULT_MODEL_KEY)

    Returns:
        ì„ë² ë”© ê²°ê³¼
    """
    return vector_db_service.embed_repository(repo_name, collection_name, model_key)


@app.task
def search_vectors(
    query: str,
    collection_name: str,
    model_key: str = DEFAULT_MODEL_KEY,
    top_k: int = 5,
    filter_expr: Optional[str] = None,
) -> SearchResult:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰ (ë°€ì§‘ + í¬ì†Œ ë²¡í„°)

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        collection_name: ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ì´ë¦„
        model_key: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ í‚¤ (ê¸°ë³¸ê°’: DEFAULT_MODEL_KEY)
        top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
        filter_expr: í•„í„° í‘œí˜„ì‹ (ì„ íƒ)

    Returns:
        ê²€ìƒ‰ ê²°ê³¼
    """
    return vector_db_service.search(query, collection_name, model_key, top_k, filter_expr)


# Repository ì²˜ë¦¬ í†µí•© ì‘ì—…
@app.task(name='rag_worker.tasks.process_repository_pipeline')
def process_repository_pipeline(
    repo_id: str,
    git_url: str,
    repo_name: str,
    model_key: str = DEFAULT_MODEL_KEY
) -> Dict[str, Any]:
    """
    Repository ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    1. Git clone
    2. Python íŒŒì‹± ë° ì²­í‚¹
    3. Vector DB ì„ë² ë”©

    Args:
        repo_id: Repository ID (UUID)
        git_url: Git repository URL
        repo_name: Repository ì´ë¦„
        model_key: ì„ë² ë”© ëª¨ë¸ í‚¤

    Returns:
        ì²˜ë¦¬ ê²°ê³¼
    """
    import os
    import logging
    from pathlib import Path
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker

    logger = logging.getLogger(__name__)

    # DATABASE_URL ì„¤ì •
    env_local_path = Path(__file__).parent.parent / '.env.local'
    logger.info(f"ğŸ” Looking for .env.local at: {env_local_path}")
    logger.info(f"ğŸ“ .env.local exists: {env_local_path.exists()}")

    if env_local_path.exists():
        # .env.local íŒŒì¼ì„ ì§ì ‘ íŒŒì‹±
        DATABASE_URL = None
        with open(env_local_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line.startswith('DATABASE_URL='):
                    DATABASE_URL = line.split('=', 1)[1]
                    break

        if DATABASE_URL:
            os.environ['DATABASE_URL'] = DATABASE_URL
            logger.info(f"âœ… Set DATABASE_URL from .env.local: {DATABASE_URL}")
        else:
            DATABASE_URL = 'postgresql://postgres:postgres@localhost:5432/ragit'
            os.environ['DATABASE_URL'] = DATABASE_URL
            logger.warning(f"âš ï¸ DATABASE_URL not found in .env.local, using default: {DATABASE_URL}")
    else:
        DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:postgres@localhost:5432/ragit')
        logger.info(f"âš ï¸ .env.local not found, using environment: {DATABASE_URL}")

    # DB helper import
    from .db_helper import RepositoryDBHelper

    # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    db = SessionLocal()
    logger.info(f"ğŸ”— Database connection created successfully")

    try:
        # 1. ìƒíƒœë¥¼ 'syncing'ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        RepositoryDBHelper.update_repository_status(db, repo_id, "syncing", "pending")

        # 2. Git Clone
        clone_result = git_service.clone_repository(git_url, repo_name)
        if not clone_result['success']:
            error_msg = f"Git clone failed: {clone_result['message']}"
            RepositoryDBHelper.update_repository_status(db, repo_id, "error", "error", error_msg)
            return {
                "success": False,
                "error": error_msg,
                "step": "clone"
            }

        # 3. Python íŒŒì¼ íŒŒì‹± ë° ì²­í‚¹
        parse_result = parser_service.parse_repository(repo_name, save_json=True)
        if not parse_result['success']:
            error_msg = f"Parsing failed: {parse_result['message']}"
            RepositoryDBHelper.update_repository_status(db, repo_id, "error", "error", error_msg)
            return {
                "success": False,
                "error": error_msg,
                "step": "parse"
            }

        # íŒŒì¼ ê°œìˆ˜ ì—…ë°ì´íŠ¸
        file_count = parse_result['total_files']
        RepositoryDBHelper.update_file_count(db, repo_id, file_count)

        # 4. Vector DB ìƒíƒœë¥¼ 'syncing'ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        RepositoryDBHelper.update_repository_status(db, repo_id, "syncing", "syncing")

        # 5. Vector DB ì„ë² ë”©
        collection_name = f"repo_{repo_id.replace('-', '_')}"
        embed_result = vector_db_service.embed_repository(repo_name, collection_name, model_key)

        if not embed_result['success']:
            error_msg = f"Embedding failed: {embed_result['message']}"
            RepositoryDBHelper.update_repository_status(db, repo_id, "active", "error", error_msg)
            return {
                "success": False,
                "error": error_msg,
                "step": "embed",
                "file_count": file_count
            }

        # 6. Collections count ì¦ê°€
        RepositoryDBHelper.increment_collections_count(db, repo_id)

        # 7. ìµœì¢… ìƒíƒœë¥¼ 'active'ë¡œ ì—…ë°ì´íŠ¸
        RepositoryDBHelper.update_repository_status(db, repo_id, "active", "active")

        return {
            "success": True,
            "repo_id": repo_id,
            "repo_name": repo_name,
            "file_count": file_count,
            "total_chunks": parse_result['total_chunks'],
            "collection_name": collection_name,
            "embedded_count": embed_result['inserted_count'],
            "message": "Repository processed successfully"
        }

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
        error_msg = f"Unexpected error: {str(e)}"
        RepositoryDBHelper.update_repository_status(db, repo_id, "error", "error", error_msg)
        return {
            "success": False,
            "error": error_msg,
            "step": "unknown"
        }
    finally:
        db.close()


# Chat RAG ì‘ì—…
@app.task(name='rag_worker.tasks.chat_query')
def chat_query(
    chat_room_id: str,
    repo_id: str,
    user_message: str,
    top_k: int = 5
) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±

    Args:
        chat_room_id: ì±„íŒ…ë°© ID
        repo_id: ë ˆí¬ì§€í† ë¦¬ ID
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        top_k: ê²€ìƒ‰í•  ì½”ë“œ ì¡°ê° ê°œìˆ˜

    Returns:
        ì‘ë‹µ ê²°ê³¼
    """
    import os
    import logging
    import json
    from pathlib import Path
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker

    logger = logging.getLogger(__name__)

    # DATABASE_URL ì„¤ì • (process_repository_pipelineê³¼ ë™ì¼í•œ ë¡œì§)
    env_local_path = Path(__file__).parent.parent / '.env.local'

    if env_local_path.exists():
        DATABASE_URL = None
        with open(env_local_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line.startswith('DATABASE_URL='):
                    DATABASE_URL = line.split('=', 1)[1]
                    break

        if DATABASE_URL:
            os.environ['DATABASE_URL'] = DATABASE_URL
            logger.info(f"âœ… Set DATABASE_URL from .env.local")
        else:
            DATABASE_URL = 'postgresql://postgres:postgres@localhost:5432/ragit'
            os.environ['DATABASE_URL'] = DATABASE_URL
            logger.warning(f"âš ï¸ DATABASE_URL not found in .env.local, using default")
    else:
        DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:postgres@localhost:5432/ragit')
        logger.info(f"âš ï¸ .env.local not found, using environment")

    # DB helper import
    from .db_helper import ChatMessageDBHelper

    # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    db = SessionLocal()
    logger.info(f"ğŸ”— Database connection created successfully")

    try:
        # 1. Vector DB ê²€ìƒ‰
        collection_name = f"repo_{repo_id.replace('-', '_')}"
        logger.info(f"ğŸ” Searching vectors in collection: {collection_name}")
        logger.info(f"ğŸ“ User query: {user_message}")

        search_result = vector_db_service.search(
            query=user_message,
            collection_name=collection_name,
            model_key=DEFAULT_MODEL_KEY,
            top_k=top_k
        )

        if not search_result['success']:
            logger.error(f"âŒ Vector search failed: {search_result.get('error')}")
            # ê²€ìƒ‰ ì‹¤íŒ¨ì‹œì—ë„ ê¸°ë³¸ ì‘ë‹µ ìƒì„±
            bot_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì½”ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            sources = None
        else:
            logger.info(f"âœ… Found {search_result['total_results']} relevant code snippets")

            # 2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±
            retrieved_codes = search_result['results'][:top_k]

            if retrieved_codes:
                try:
                    # ë””ë²„ê¹…: ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
                    logger.info(f"ğŸ” Retrieved codes sample:")
                    for i, code in enumerate(retrieved_codes[:2], 1):
                        logger.info(f"  [{i}] {code.get('name')} ({code.get('file_path')})")
                        logger.info(f"      Code length: {len(code.get('code', ''))} chars")
                        logger.info(f"      Has code: {'code' in code}")
                        logger.info(f"      Code preview: {code.get('code', '')[:100]}")

                    # 2-1. PromptGeneratorë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                    logger.info(f"ğŸ“ Generating prompt from {len(retrieved_codes)} code snippets")
                    prompt = prompt_service.create(docs=retrieved_codes, query=user_message)

                    # ë””ë²„ê¹…: ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸
                    logger.info(f"ğŸ“„ Generated prompt length: {len(prompt)} chars")
                    logger.info(f"ğŸ“„ Prompt preview (first 500 chars):\n{prompt[:500]}")

                    # 2-2. AskQuestionìœ¼ë¡œ LLM ì‘ë‹µ ë°›ê¸°
                    logger.info(f"ğŸ¤– Calling LLM API...")
                    bot_response = call_service.ask_question(
                        prompt=prompt,
                        use_stream=False,
                        model="gpt-4o-mini",
                        temperature=0.1,
                        max_tokens=2048
                    )
                    logger.info(f"âœ… LLM response received")
                    logger.info(f"ğŸ“ Response preview: {bot_response[:200]}")

                    # sourcesë¥¼ JSON ë¬¸ìì—´ë¡œ ì €ì¥
                    sources = json.dumps([
                        f"{code['file_path']}:{code['start_line']}-{code['end_line']}"
                        for code in retrieved_codes
                    ], ensure_ascii=False)

                except Exception as llm_error:
                    logger.error(f"âŒ LLM API call failed: {str(llm_error)}")

                    # API KEY ì—†ìŒ ì—¬ë¶€ ì²´í¬
                    is_api_key_missing = "OPENAI_API_KEY" in str(llm_error)

                    # LLM í˜¸ì¶œ ì‹¤íŒ¨ì‹œ RAG ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
                    code_summary = []
                    for i, code in enumerate(retrieved_codes, 1):
                        file_info = code.get('file_path', 'Unknown')
                        name_info = code.get('name', 'N/A')
                        if name_info:
                            code_summary.append(f"{i}. **{name_info}** (`{file_info}:{code.get('start_line', 0)}-{code.get('end_line', 0)}`)")
                        else:
                            code_summary.append(f"{i}. `{file_info}:{code.get('start_line', 0)}-{code.get('end_line', 0)}`")

                    if is_api_key_missing:
                        error_msg = "âš ï¸ **OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**"
                        instruction_msg = "í™˜ê²½ ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ë©´ AI ê¸°ë°˜ ì½”ë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    else:
                        error_msg = "âš ï¸ **LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.**"
                        instruction_msg = f"ì˜¤ë¥˜ ë‚´ìš©: {str(llm_error)[:100]}"

                    bot_response = f"""ì§ˆë¬¸í•´ì£¼ì‹  ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì½”ë“œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.

**ğŸ” RAG ê²€ìƒ‰ ê²°ê³¼ ({len(retrieved_codes)}ê°œ ë°œê²¬):**

{chr(10).join(code_summary)}

---

{error_msg}

{instruction_msg}

ê²€ìƒ‰ëœ ì½”ë“œ ì¡°ê°ë“¤ì„ ì°¸ê³ í•˜ì‹œë©´ ë‹µë³€ì„ ì–»ìœ¼ì‹¤ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤."""

                    sources = json.dumps([
                        f"{code['file_path']}:{code['start_line']}-{code['end_line']}"
                        for code in retrieved_codes
                    ], ensure_ascii=False)
            else:
                bot_response = "ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì½”ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?"
                sources = None

        # 3. Bot ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥
        logger.info(f"ğŸ’¾ Saving bot response to database")

        bot_message = ChatMessageDBHelper.create_bot_message(
            db=db,
            chat_room_id=chat_room_id,
            content=bot_response,
            sources=sources
        )

        logger.info(f"âœ… Bot message saved with ID: {bot_message['id']}")

        return {
            "success": True,
            "chat_room_id": chat_room_id,
            "bot_message_id": bot_message['id'],
            "retrieved_count": search_result.get('total_results', 0) if search_result['success'] else 0,
            "message": "Chat query processed successfully"
        }

    except Exception as e:
        logger.error(f"âŒ Error processing chat query: {str(e)}", exc_info=True)

        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ bot ì‘ë‹µìœ¼ë¡œ ì €ì¥
        try:
            ChatMessageDBHelper.create_bot_message(
                db=db,
                chat_room_id=chat_room_id,
                content=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                sources=None
            )
        except:
            pass

        return {
            "success": False,
            "error": str(e),
            "chat_room_id": chat_room_id
        }

    finally:
        db.close()


### ragit_sdk/tests/create_prompt.py
@app.task
def create_prompt(
    docs: List[SearchResult],
    query: str,
) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì´ìš©í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±

    Args:
        SearchResult: ê²€ìƒ‰ ê²°ê³¼
        query: ê²€ìƒ‰ ì¿¼ë¦¬

    Returns:
        ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
    """
    return prompt_service.create(docs, query)

### ragit_sdk/tests/ask_question.py
@app.task
def call_llm(
        prompt: str, 
        use_stream: Optional[bool] = False, 
        model: Optional[str] = "gpt-3.5-turbo", 
        temperature: Optional[float] = 0.1, 
        max_tokens: Optional[int] = 1024,
) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì´ìš©í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±

    Args:
        SearchResult: ê²€ìƒ‰ ê²°ê³¼
        query: ê²€ìƒ‰ ì¿¼ë¦¬

    Returns:
        ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
    """
    return call_service.ask_question(prompt=prompt, use_stream=use_stream, model=model, temperature=temperature, max_tokens=max_tokens)



### ragit_sdk/tests/diff_file.py
@app.task(name='rag_worker.tasks.run_git_diff')
def run_git_diff(repo_name: str):
    """
    GitServiceì˜ diff_files ë©”ì„œë“œë¥¼ í…ŒìŠ¤íŠ¸
    """
    return git_service.diff_files(repo_name)


### ragit_sdk/tests/embedding.py
@app.task(name='rag_worker.tasks.parse_and_embed_repository')
def parse_and_embed_repository(repo_name: str, collection_name: str, model_key: str, save_json: bool = True):
    """
    ë ˆí¬ì§€í† ë¦¬ë¥¼ íŒŒì‹±í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ì¦‰ì‹œ Vector DBì— ì„ë² ë”©í•˜ëŠ” í†µí•© Testìš© Celery Task
    """
    # --- 1ë‹¨ê³„: ì½”ë“œ íŒŒì‹± ë° ì²­í‚¹ ---
    parse_result = parser_service.parse_repository(
        repo_name=repo_name,
        save_json=save_json
    )

    if not parse_result.get('success'):
        # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì¦‰ì‹œ ë°˜í™˜
        return {
            "success": False,
            "step": "parse",
            "error": parse_result.get('message'),
            "repo_name": repo_name
        }

    # --- 2ë‹¨ê³„: Vector DB ì„ë² ë”© ---
    embed_result = vector_db_service.embed_repository(
        repo_name=repo_name,
        collection_name=collection_name,
        model_key=model_key
    )

    if not embed_result.get('success'):
        return {
            "success": False,
            "step": "embed",
            "error": embed_result.get('message'),
            "repo_name": repo_name
        }

    # ìµœì¢… ì„±ê³µ ê²°ê³¼ ë°˜í™˜
    return {
        "success": True,
        "repo_name": repo_name,
        "collection_name": collection_name,
        "parsed_files": parse_result.get('total_files'),
        "total_chunks": embed_result.get('total_chunks'),
        "embedded_count": embed_result.get('inserted_count'),
        "message": "Repository parsed and embedded successfully."
    }


# repository ìµœì‹  ë™ê¸°í™” í†µí•© ì‘ì—… (update ê¸°ëŠ¥)
@app.task(name='rag_worker.tasks.update_repository_pipeline')
def update_repository_pipeline(
    repo_id: str,
    repo_name: str,
    collection_name: str,
    save_json: bool = True,
    model_key: str = DEFAULT_MODEL_KEY,
) -> Dict[str, Any]:
    """
    Repository ì—…ë°ì´íŠ¸ ìµœì í™” íŒŒì´í”„ë¼ì¸
    1. Local vs Remote diff ì°¾ê¸°
    2. Git Pull ë¡œ ìµœì‹  ì½”ë“œ ë°›ê¸°
    3. Vector DBì—ì„œ ë³€ê²½ëœ íŒŒì¼ì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    4. ë ˆí¬ì§€í† ë¦¬ ì „ì²´ ì¬-íŒŒì‹±í•˜ì—¬ JSON íŒŒì¼ ìµœì‹ í™”
    5. ë³€ê²½ëœ JSON íŒŒì¼ë§Œ ë‹¤ì‹œ ì„ë² ë”©
    
    Args:
        repo_id: Repository ID (UUID)
        repo_name: Repository ì´ë¦„
        collection_name: Vector DB ì»¬ë ‰ì…˜ ì´ë¦„
        save_json: JSON íŒŒì¼ë¡œ ì €ì¥ ì—¬ë¶€
        model_key: ì„ë² ë”© ëª¨ë¸ í‚¤

    Returns:
        ì²˜ë¦¬ ê²°ê³¼
    """
    import os
    import logging
    from pathlib import Path
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker

    logger = logging.getLogger(__name__)


    env_local_path = Path(__file__).parent.parent / '.env.local'
    if env_local_path.exists():
        DATABASE_URL = None
        with open(env_local_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line.startswith('DATABASE_URL='):
                    DATABASE_URL = line.split('=', 1)[1]
                    break
        if DATABASE_URL:
            os.environ['DATABASE_URL'] = DATABASE_URL
        else:
            DATABASE_URL = 'postgresql://postgres:postgres@localhost:5432/ragit'
            os.environ['DATABASE_URL'] = DATABASE_URL
    else:
        DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:postgres@localhost:5432/ragit')
    
    from backend.services.repository_service import RepositoryService

    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    db = SessionLocal()
    logger.info(f"ğŸ”— [{repo_name}] Database connection created for update pipeline.")

    try:
        # 1. ìƒíƒœë¥¼ 'updating'ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        RepositoryService.update_repository_status(db, repo_id, "updating", "pending")

        # 2. PULL í•˜ê¸° ì „, ë¨¼ì € ë³€ê²½ë  íŒŒì¼ ëª©ë¡(diff) í™•ë³´
        logger.info(f"[{repo_name}] Step 1: Finding diff...")
        diff_result = git_service.diff_files(repo_name)
        if not diff_result.get('success'):
            RepositoryService.update_repository_status(db, repo_id, "active", "error")
            return {"success": False, "error": f"Failed to get diff: {diff_result.get('error')}", "step": "diff"}
        
        files_to_update = diff_result.get("files", [])
        logger.info(f"[{repo_name}] Found {len(files_to_update)} files to update.")

        # 3. Git Pull ë¡œ ë¡œì»¬ ì½”ë“œ ìµœì‹ í™”
        logger.info(f"[{repo_name}] Step 2: Pulling latest changes.")
        pull_result = git_service.pull_repository(repo_name)
        if not pull_result.get('success'):
            RepositoryService.update_repository_status(db, repo_id, "error", "error")
            return {"success": False, "error": f"Git pull failed: {pull_result.get('error')}", "step": "pull"}
        
        # 4. Vector DB ìƒíƒœë¥¼ 'updating'ìœ¼ë¡œ ë³€ê²½
        RepositoryService.update_repository_status(db, repo_id, "updating", "updating")

        # 5. í™•ë³´í•œ ëª©ë¡ìœ¼ë¡œ Vector DBì˜ ê¸°ì¡´ ì—”í‹°í‹° ì‚­ì œ
        deleted_count = 0
        if files_to_update:
            num_files_to_delete = len(files_to_update)
            logger.info(f"[{repo_name}] Step 3: Deleting old entities...")
            delete_result = vector_db_service.delete_entities(
                collection_name=collection_name, 
                source_files=files_to_update
            )
            if not delete_result.get('success'):
                RepositoryService.update_repository_status(db, repo_id, "active", "error")
                return {"success": False, "error": f"Failed to delete entities: {delete_result.get('error')}", "step": "delete_entities"}
            deleted_count = num_files_to_delete
            logger.info(f"[{repo_name}] Deleted {deleted_count} old entities.")
        else:
            logger.info(f"[{repo_name}] Step 3: No entities to delete, skipping.")

        # 6. ìµœì‹  ì½”ë“œë¡œ ë ˆí¬ì§€í† ë¦¬ ì „ì²´ë¥¼ ë‹¤ì‹œ íŒŒì‹± (JSON íŒŒì¼ë“¤ì˜ ë‚´ìš©ì„ ìµœì‹ ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ í•„ìˆ˜)
        logger.info(f"[{repo_name}] Step 4: Re-parsing entire repository to update JSON files.")
        parse_result = parser_service.parse_repository(repo_name, save_json)
        if not parse_result.get('success'):
            RepositoryService.update_repository_status(db, repo_id, "error", "error")
            return {"success": False, "error": f"Parsing failed: {parse_result.get('message')}", "step": "parse"}
        
        file_count = parse_result.get('total_files', 0)
        RepositoryService.update_file_count(db, repo_id, file_count)

        # 7. ë³€ê²½ëœ íŒŒì¼ ëª©ë¡(files_to_update)ì— í•´ë‹¹í•˜ëŠ” JSON íŒŒì¼ë§Œ ë‹¤ì‹œ ì„ë² ë”©
        logger.info(f"[{repo_name}] Step 5: Re-embedding only changed files...")
        total_embedded_count = 0
        if files_to_update:
            # íŒŒì‹±ëœ JSON íŒŒì¼ì´ ì €ì¥ëœ ê¸°ë³¸ ê²½ë¡œ (parser_serviceì˜ ê²½ë¡œ êµ¬ì¡°ì— ë§ì¶°ì•¼ í•¨)
            parsed_repo_path = Path(f"parsed_repository/{repo_name}")

            for json_filename in files_to_update:
                json_file_path = parsed_repo_path / json_filename
                
                if not json_file_path.exists():
                    logger.warning(f"[{repo_name}] Parsed file {json_file_path} not found. It might have been deleted. Skipping embedding.")
                    continue

                embed_result = vector_db_service.embed_documents(
                    json_path=str(json_file_path),
                    collection_name=collection_name,
                    model_key=model_key
                )
                if not embed_result.get('success'):
                    RepositoryService.update_repository_status(db, repo_id, "active", "error")
                    return {"success": False, "error": f"Embedding failed for {json_filename}", "step": "embed"}
                
                total_embedded_count += embed_result.get('inserted_count', 0)
            
            logger.info(f"[{repo_name}] Re-embedded {total_embedded_count} new chunks from {len(files_to_update)} files.")
        else:
            logger.info(f"[{repo_name}] Step 5: No files to re-embed, skipping.")


        # 8. ìµœì¢… ìƒíƒœë¥¼ 'active'ë¡œ ì—…ë°ì´íŠ¸
        RepositoryService.update_repository_status(db, repo_id, "active", "active")
        logger.info(f"[{repo_name}] Update pipeline finished successfully.")

        return {
            "success": True,
            "repo_id": repo_id,
            "repo_name": repo_name,
            "file_count": file_count,
            "deleted_count": deleted_count,
            "embedded_count": total_embedded_count,
            "message": "Repository updated successfully"
        }

    except Exception as e:
        logger.error(f"[{repo_name}] An unexpected error occurred in update pipeline: {e}", exc_info=True)
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
        RepositoryService.update_repository_status(db, repo_id, "error", "error")
        return {
            "success": False,
            "error": str(e),
            "step": "unknown"
        }
    finally:
        db.close()
        logger.info(f"[{repo_name}] Database connection closed for update pipeline.")